{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uU4CnW3VHSIq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Kpl74T4aJnhb"
      },
      "outputs": [],
      "source": [
        "DATASET_ROOT = 'D:\\X-ITE Pain'\n",
        "CLASS_NAMES = ['low_pain', 'medium_pain']\n",
        "AUDIO_SUBDIR = \"audio\"\n",
        "AUDIO_EXT = \".wav\"\n",
        "SAMPLE_RATE = 16000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "46uGKSLBLj3w"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "yamnet_model = hub.load(\"https://tfhub.dev/google/yamnet/1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3ybFJnz5Ncbd"
      },
      "outputs": [],
      "source": [
        "def extract_embedding(audio_file):\n",
        "    wav, sr = librosa.load(audio_file, sr=SAMPLE_RATE)\n",
        "    if wav.ndim > 1:\n",
        "        wav = librosa.to_mono(wav)\n",
        "    waveform = wav.astype(np.float32)\n",
        "    _, embeddings, _ = yamnet_model(waveform)\n",
        "    return tf.reduce_mean(embeddings, axis=0).numpy()\n",
        "\n",
        "def collect_files_and_labels(dataset_root):\n",
        "    files, labels = [], []\n",
        "    for cls in CLASS_NAMES:\n",
        "        cls_audio_dir = os.path.join(dataset_root, cls, AUDIO_SUBDIR)\n",
        "        if not os.path.isdir(cls_audio_dir):\n",
        "            continue\n",
        "        # Recursively search for .wav files in all subject subfolders\n",
        "        for root, dirs, filenames in os.walk(cls_audio_dir):\n",
        "            for fname in filenames:\n",
        "                if fname.endswith(AUDIO_EXT):\n",
        "                    files.append(os.path.join(root, fname))\n",
        "                    labels.append(cls)\n",
        "    return files, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z6-NgKGObqA",
        "outputId": "9949b777-2709-47ae-8650-3dec938e3dbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total audio samples found: 2638\n",
            "low_pain: 1318 samples\n",
            "medium_pain: 1320 samples\n"
          ]
        }
      ],
      "source": [
        "files, labels = collect_files_and_labels(DATASET_ROOT)\n",
        "print(f\"Total audio samples found: {len(files)}\")\n",
        "for cls in CLASS_NAMES:\n",
        "    print(f\"{cls}: {labels.count(cls)} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xid6sFMTa5WH",
        "outputId": "6ecfcafc-2faa-496f-a1f6-2caec7eb383f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Extracting embeddings: 100%|██████████| 2638/2638 [01:28<00:00, 29.71it/s]\n"
          ]
        }
      ],
      "source": [
        "embeddings = []\n",
        "for f in tqdm(files, desc=\"Extracting embeddings\"):\n",
        "    emb = extract_embedding(f)\n",
        "    embeddings.append(emb)\n",
        "X = np.stack(embeddings)\n",
        "y = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxOTIn-hcyZ3",
        "outputId": "58a9a615-59e2-45dd-f4e7-4d219bfec8d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 2110\n",
            "Test samples: 528\n",
            "Label mapping: {np.str_('low_pain'): np.int64(0), np.str_('medium_pain'): np.int64(1)}\n"
          ]
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Training samples:\", X_train.shape[0])\n",
        "print(\"Test samples:\", X_test.shape[0])\n",
        "print(\"Label mapping:\", dict(zip(le.classes_, le.transform(le.classes_))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7fdkTj6vAgB",
        "outputId": "0a8f7bbf-afde-4aa0-de21-cba141b05058"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    low_pain       0.50      0.39      0.43       264\n",
            " medium_pain       0.50      0.61      0.55       264\n",
            "\n",
            "    accuracy                           0.50       528\n",
            "   macro avg       0.50      0.50      0.49       528\n",
            "weighted avg       0.50      0.50      0.49       528\n",
            "\n",
            "Confusion Matrix:\n",
            "\n",
            "[[102 162]\n",
            " [104 160]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Set max_iter to 10 (epochs)\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(256,32), max_iter=350, random_state=42)\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate on test set\n",
        "y_pred = mlp.predict(X_test)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "print(\"Confusion Matrix:\\n\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxo-4padz5u7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
