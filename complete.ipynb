{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27f0f5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading segments from: D:\\bio_s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "low_pain/S008: 100%|██████████| 60/60 [00:00<00:00, 3641.26it/s]\n",
      "low_pain/S009: 100%|██████████| 59/59 [00:00<00:00, 2676.73it/s]\n",
      "low_pain/S019: 100%|██████████| 60/60 [00:00<00:00, 5621.51it/s]\n",
      "low_pain/S026: 100%|██████████| 60/60 [00:00<00:00, 2062.47it/s]\n",
      "low_pain/S034: 100%|██████████| 60/60 [00:00<00:00, 4025.18it/s]\n",
      "low_pain/S045: 100%|██████████| 60/60 [00:00<00:00, 2777.50it/s]\n",
      "low_pain/S049: 100%|██████████| 60/60 [00:00<00:00, 4762.47it/s]\n",
      "low_pain/S051: 100%|██████████| 60/60 [00:00<00:00, 3557.86it/s]\n",
      "low_pain/S052: 100%|██████████| 60/60 [00:00<00:00, 1915.70it/s]\n",
      "low_pain/S057: 100%|██████████| 60/60 [00:00<00:00, 3335.12it/s]\n",
      "low_pain/S068: 100%|██████████| 59/59 [00:00<00:00, 3825.32it/s]\n",
      "low_pain/S069: 100%|██████████| 60/60 [00:00<00:00, 3462.88it/s]\n",
      "low_pain/S070: 100%|██████████| 60/60 [00:00<00:00, 3804.24it/s]\n",
      "low_pain/S072: 100%|██████████| 60/60 [00:00<00:00, 1856.87it/s]\n",
      "low_pain/S076: 100%|██████████| 60/60 [00:00<00:00, 3618.64it/s]\n",
      "low_pain/S087: 100%|██████████| 60/60 [00:00<00:00, 3668.33it/s]\n",
      "low_pain/S095: 100%|██████████| 60/60 [00:00<00:00, 3048.00it/s]\n",
      "low_pain/S107: 100%|██████████| 60/60 [00:00<00:00, 4185.86it/s]\n",
      "low_pain/S110: 100%|██████████| 60/60 [00:00<00:00, 1839.85it/s]\n",
      "low_pain/S114: 100%|██████████| 60/60 [00:00<00:00, 3530.71it/s]\n",
      "low_pain/S126: 100%|██████████| 60/60 [00:00<00:00, 3675.67it/s]\n",
      "low_pain/S134: 100%|██████████| 60/60 [00:00<00:00, 3514.19it/s]\n",
      "med_pain/S008: 100%|██████████| 60/60 [00:00<00:00, 3540.14it/s]\n",
      "med_pain/S009: 100%|██████████| 60/60 [00:00<00:00, 3621.71it/s]\n",
      "med_pain/S019: 100%|██████████| 60/60 [00:00<00:00, 3237.43it/s]\n",
      "med_pain/S026: 100%|██████████| 60/60 [00:00<00:00, 3806.89it/s]\n",
      "med_pain/S034: 100%|██████████| 60/60 [00:00<00:00, 3449.31it/s]\n",
      "med_pain/S045: 100%|██████████| 60/60 [00:00<00:00, 1894.56it/s]\n",
      "med_pain/S049: 100%|██████████| 60/60 [00:00<00:00, 3366.13it/s]\n",
      "med_pain/S051: 100%|██████████| 60/60 [00:00<00:00, 3731.14it/s]\n",
      "med_pain/S052: 100%|██████████| 60/60 [00:00<00:00, 3647.49it/s]\n",
      "med_pain/S057: 100%|██████████| 60/60 [00:00<00:00, 3615.16it/s]\n",
      "med_pain/S068: 100%|██████████| 60/60 [00:00<00:00, 3383.78it/s]\n",
      "med_pain/S069: 100%|██████████| 60/60 [00:00<00:00, 3603.04it/s]\n",
      "med_pain/S070: 100%|██████████| 60/60 [00:00<00:00, 3506.16it/s]\n",
      "med_pain/S072: 100%|██████████| 60/60 [00:00<00:00, 3766.44it/s]\n",
      "med_pain/S076: 100%|██████████| 60/60 [00:00<00:00, 1846.50it/s]\n",
      "med_pain/S087: 100%|██████████| 60/60 [00:00<00:00, 3347.63it/s]\n",
      "med_pain/S095: 100%|██████████| 60/60 [00:00<00:00, 3352.67it/s]\n",
      "med_pain/S107: 100%|██████████| 60/60 [00:00<00:00, 3459.03it/s]\n",
      "med_pain/S110: 100%|██████████| 60/60 [00:00<00:00, 3406.36it/s]\n",
      "med_pain/S114: 100%|██████████| 60/60 [00:00<00:00, 3345.58it/s]\n",
      "med_pain/S126: 100%|██████████| 60/60 [00:00<00:00, 3394.96it/s]\n",
      "med_pain/S134: 100%|██████████| 60/60 [00:00<00:00, 4175.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2638 segments.\n",
      "Denoising all segments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2638/2638 [00:03<00:00, 665.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2638/2638 [00:00<00:00, 6612.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing features...\n",
      "Splitting train/test...\n",
      "Running grid search...\n",
      "Predicting on test set...\n",
      "Accuracy: 0.5429292929292929\n",
      "Precision: 0.5430875576036865\n",
      "Recall: 0.5429292929292929\n",
      "F1 Score: 0.5425091911764707\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score     support\n",
      "0              0.545699  0.512626  0.528646  396.000000\n",
      "1              0.540476  0.573232  0.556373  396.000000\n",
      "accuracy       0.542929  0.542929  0.542929    0.542929\n",
      "macro avg      0.543088  0.542929  0.542509  792.000000\n",
      "weighted avg   0.543088  0.542929  0.542509  792.000000\n",
      "\n",
      "Confusion Matrix:\n",
      "          low_pain  med_pain\n",
      "low_pain       203       193\n",
      "med_pain       169       227\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top features:\n",
      "    feature  importance\n",
      "0   ch0_min    0.117023\n",
      "1   ch0_max    0.114501\n",
      "2   ch3_min    0.101126\n",
      "3   ch0_std    0.100936\n",
      "4   ch1_min    0.100893\n",
      "5   ch3_std    0.095280\n",
      "6   ch4_std    0.093982\n",
      "7   ch4_min    0.092901\n",
      "8  ch0_mean    0.092256\n",
      "9   ch3_max    0.091102\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")\n",
    "\n",
    "# --------- 1. Denoising Functions ---------\n",
    "def wavelet_denoise(signal, wavelet='db4', level=None, thresholding='soft', threshold_scale=1.0):\n",
    "    coeffs = pywt.wavedec(signal, wavelet=wavelet, level=level)\n",
    "    detail_coeffs = coeffs[-1]\n",
    "    sigma = np.median(np.abs(detail_coeffs)) / 0.6745\n",
    "    uthresh = threshold_scale * sigma * np.sqrt(2 * np.log(len(signal)))\n",
    "    new_coeffs = [coeffs[0]]  # Keep approximation untouched\n",
    "    for c in coeffs[1:]:\n",
    "        new_c = pywt.threshold(c, value=uthresh, mode=thresholding)\n",
    "        new_coeffs.append(new_c)\n",
    "    denoised = pywt.waverec(new_coeffs, wavelet=wavelet)\n",
    "    return denoised[:len(signal)]\n",
    "\n",
    "def denoise_multichannel(data, wavelet='db4', level=None, thresholding='soft', threshold_scale=1.0):\n",
    "    n_channels = data.shape[1]\n",
    "    denoised_data = np.zeros_like(data)\n",
    "    for ch in range(n_channels):\n",
    "        denoised_data[:, ch] = wavelet_denoise(\n",
    "            data[:, ch], \n",
    "            wavelet=wavelet, \n",
    "            level=level, \n",
    "            thresholding=thresholding,\n",
    "            threshold_scale=threshold_scale\n",
    "        )\n",
    "    return denoised_data\n",
    "\n",
    "# --------- 2. Feature Extraction ---------\n",
    "def extract_features(segment):\n",
    "    \"\"\"\n",
    "    Replace or extend with your real features!\n",
    "    Here: mean, std, max, min for each channel.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    for i in range(segment.shape[1]):\n",
    "        ch = segment[:, i]\n",
    "        features[f'ch{i}_mean'] = np.mean(ch)\n",
    "        features[f'ch{i}_std'] = np.std(ch)\n",
    "        features[f'ch{i}_max'] = np.max(ch)\n",
    "        features[f'ch{i}_min'] = np.min(ch)\n",
    "    return features\n",
    "\n",
    "# --------- 3. Normalization ---------\n",
    "def zscore_normalize_segment(segment_features):\n",
    "    values = np.array(list(segment_features.values()), dtype=float)\n",
    "    mu = values.mean()\n",
    "    sigma = values.std()\n",
    "    norm_values = (values - mu) / sigma if sigma > 0 else np.zeros_like(values)\n",
    "    return dict(zip(segment_features.keys(), norm_values))\n",
    "\n",
    "def normalize_features_batch(features_list):\n",
    "    normalized = [zscore_normalize_segment(f) for f in features_list]\n",
    "    df = pd.DataFrame(normalized)\n",
    "    return df\n",
    "\n",
    "# --------- 4. Feature Selector ---------\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, method='kbest', k=10, estimator=None, score_func='f_classif'):\n",
    "        self.method = method\n",
    "        self.k = k\n",
    "        self.estimator = estimator\n",
    "        self.score_func = score_func\n",
    "        self.selector_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if self.method == 'kbest':\n",
    "            func = f_classif if self.score_func == 'f_classif' else mutual_info_classif\n",
    "            self.selector_ = SelectKBest(score_func=func, k=self.k)\n",
    "        elif self.method == 'rfe':\n",
    "            base_est = self.estimator if self.estimator is not None else LogisticRegression(max_iter=1000)\n",
    "            self.selector_ = RFE(estimator=base_est, n_features_to_select=self.k)\n",
    "        elif self.method == 'none':\n",
    "            self.selector_ = None\n",
    "            return self\n",
    "        else:\n",
    "            raise ValueError(\"Unknown feature selection method.\")\n",
    "        self.selector_.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.selector_ is None:\n",
    "            return X\n",
    "        return self.selector_.transform(X)\n",
    "\n",
    "    def get_support(self):\n",
    "        if self.selector_ is None:\n",
    "            return np.arange(X.shape[1])\n",
    "        return self.selector_.get_support()\n",
    "\n",
    "# --------- 5. Model Pipeline ---------\n",
    "def build_model_pipeline(\n",
    "    feature_selection_method='kbest',\n",
    "    k_features=10,\n",
    "    selector_score_func='f_classif',\n",
    "    classifier='rf',\n",
    "    random_state=42\n",
    "):\n",
    "    if classifier == 'logreg':\n",
    "        clf = LogisticRegression(max_iter=1000, random_state=random_state)\n",
    "    elif classifier == 'rf':\n",
    "        clf = RandomForestClassifier(random_state=random_state)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown classifier\")\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_selection', FeatureSelector(\n",
    "            method=feature_selection_method,\n",
    "            k=k_features,\n",
    "            estimator=clf if feature_selection_method == 'rfe' else None,\n",
    "            score_func=selector_score_func)),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "def run_grid_search(\n",
    "    X, y,\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv_folds=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy'\n",
    "):\n",
    "    cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=cv, n_jobs=n_jobs, scoring=scoring, refit=True)\n",
    "    grid.fit(X, y)\n",
    "    return grid\n",
    "\n",
    "# --------- 6. Feature Importance ---------\n",
    "def get_feature_importance(model, feature_names=None):\n",
    "    selector = model.best_estimator_.named_steps['feature_selection']\n",
    "    X_support = None\n",
    "    if hasattr(selector, 'get_support'):\n",
    "        X_support = selector.get_support()\n",
    "    if feature_names is not None and X_support is not None:\n",
    "        selected_names = np.array(feature_names)[X_support]\n",
    "    elif X_support is not None:\n",
    "        selected_names = [f'f{i}' for i in range(np.sum(X_support))]\n",
    "    else:\n",
    "        selected_names = feature_names if feature_names is not None else [f'f{i}' for i in range(model.best_estimator_.named_steps['scaler'].n_features_in_)]\n",
    "    clf = model.best_estimator_.named_steps['classifier']\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        importances = clf.feature_importances_\n",
    "    elif hasattr(clf, 'coef_'):\n",
    "        importances = np.abs(clf.coef_).ravel()\n",
    "    else:\n",
    "        raise AttributeError(\"Classifier does not provide feature importance or coefficients.\")\n",
    "    importance_df = pd.DataFrame({\n",
    "        \"feature\": selected_names,\n",
    "        \"importance\": importances\n",
    "    }).sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "    return importance_df\n",
    "\n",
    "# --------- 7. Metrics & Confusion Matrix ---------\n",
    "def compute_metrics(y_true, y_pred, labels=None, average='weighted'):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=average, zero_division=0)\n",
    "    cls_report = classification_report(y_true, y_pred, zero_division=0, output_dict=True)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    metrics_dict = {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1_score\": f1,\n",
    "        \"classification_report\": cls_report,\n",
    "        \"confusion_matrix\": cm,\n",
    "    }\n",
    "    return metrics_dict\n",
    "\n",
    "def print_metrics(metrics_dict, label_names=None):\n",
    "    print(\"Accuracy:\", metrics_dict[\"accuracy\"])\n",
    "    print(\"Precision:\", metrics_dict[\"precision\"])\n",
    "    print(\"Recall:\", metrics_dict[\"recall\"])\n",
    "    print(\"F1 Score:\", metrics_dict[\"f1_score\"])\n",
    "    print(\"\\nClassification Report:\")\n",
    "    report = metrics_dict[\"classification_report\"]\n",
    "    if isinstance(report, dict):\n",
    "        print(pd.DataFrame(report).transpose())\n",
    "    else:\n",
    "        print(report)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = metrics_dict[\"confusion_matrix\"]\n",
    "    if label_names is not None:\n",
    "        df_cm = pd.DataFrame(cm, index=label_names, columns=label_names)\n",
    "        print(df_cm)\n",
    "    else:\n",
    "        print(cm)\n",
    "\n",
    "def plot_confusion_matrix(metrics_dict, label_names=None, normalize=False, cmap='Blues', title='Confusion Matrix'):\n",
    "    cm = metrics_dict[\"confusion_matrix\"]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        fmt = '.2f'\n",
    "    else:\n",
    "        fmt = 'd'\n",
    "    fig, ax = plt.subplots(figsize=(6, 5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    if label_names is not None:\n",
    "        ax.set(xticks=np.arange(cm.shape[1]), yticks=np.arange(cm.shape[0]),\n",
    "               xticklabels=label_names, yticklabels=label_names, title=title, ylabel='True label', xlabel='Predicted label')\n",
    "        plt.xticks(rotation=45)\n",
    "    else:\n",
    "        ax.set(title=title, ylabel='True label', xlabel='Predicted label')\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt), ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --------- 8. Data Loading ---------\n",
    "def load_all_segments(root_dir):\n",
    "    \"\"\"\n",
    "    Walks the directory tree and loads all .mat segment files.\n",
    "    Returns:\n",
    "        - segments: list of np.ndarray, each (10000, 5)\n",
    "        - labels: list of str, e.g. \"low_pain\", \"med_pain\", etc\n",
    "        - subject_ids: list of str, e.g. \"S008\" etc\n",
    "        - file_paths: list of str, original paths (optional, for reference)\n",
    "    \"\"\"\n",
    "    segments = []\n",
    "    labels_list = []\n",
    "    subject_ids = []\n",
    "    file_paths = []\n",
    "    pain_levels = [d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))]\n",
    "    for pain_level in pain_levels:\n",
    "        pain_path = os.path.join(root_dir, pain_level)\n",
    "        for subject in os.listdir(pain_path):\n",
    "            subject_path = os.path.join(pain_path, subject)\n",
    "            if not os.path.isdir(subject_path):\n",
    "                continue\n",
    "            mat_files = glob(os.path.join(subject_path, \"*.mat\"))\n",
    "            for mfile in tqdm(mat_files, desc=f\"{pain_level}/{subject}\"):\n",
    "                try:\n",
    "                    mat = loadmat(mfile)\n",
    "                    data = mat['data'] # shape (10000, 5)\n",
    "                    segments.append(data.astype(np.float32))\n",
    "                    labels_list.append(pain_level)\n",
    "                    subject_ids.append(subject)\n",
    "                    file_paths.append(mfile)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {mfile}: {e}\")\n",
    "    return segments, labels_list, subject_ids, file_paths\n",
    "\n",
    "# --------- 9. Main Pipeline ---------\n",
    "if __name__ == \"__main__\":\n",
    "    # ---- 9.1 Load Data ----\n",
    "    root_dir = r\"D:\\bio_s\"  # <-- Modify if needed\n",
    "    print(\"Loading segments from:\", root_dir)\n",
    "    segments, pain_labels, subject_ids, file_paths = load_all_segments(root_dir)\n",
    "    print(f\"Loaded {len(segments)} segments.\")\n",
    "\n",
    "    # Encode pain labels as integers\n",
    "    unique_pain_levels = sorted(list(set(pain_labels)))\n",
    "    pain_label_to_int = {lbl: i for i, lbl in enumerate(unique_pain_levels)}\n",
    "    y = np.array([pain_label_to_int[lbl] for lbl in pain_labels])\n",
    "    label_names = unique_pain_levels\n",
    "\n",
    "    # ---- 9.2 Denoise ----\n",
    "    print(\"Denoising all segments...\")\n",
    "    denoised_segments = [denoise_multichannel(seg) for seg in tqdm(segments)]\n",
    "\n",
    "    # ---- 9.3 Feature Extraction ----\n",
    "    print(\"Extracting features...\")\n",
    "    features_list = [extract_features(seg) for seg in tqdm(denoised_segments)]\n",
    "\n",
    "    # ---- 9.4 Normalization ----\n",
    "    print(\"Normalizing features...\")\n",
    "    norm_df = normalize_features_batch(features_list)\n",
    "    feature_names = norm_df.columns.tolist()\n",
    "\n",
    "    # ---- 9.5 Train/test split ----\n",
    "    print(\"Splitting train/test...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(norm_df, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "    # ---- 9.6 Build model pipeline and grid search ----\n",
    "    pipeline = build_model_pipeline(\n",
    "        feature_selection_method='kbest',\n",
    "        k_features=10,\n",
    "        selector_score_func='f_classif',\n",
    "        classifier='rf'\n",
    "    )\n",
    "    param_grid = {\n",
    "        'feature_selection__k': [5, 10, 15],\n",
    "        'classifier__n_estimators': [100, 200]\n",
    "    }\n",
    "    print(\"Running grid search...\")\n",
    "    best_model = run_grid_search(X_train, y_train, pipeline, param_grid)\n",
    "\n",
    "    # ---- 9.7 Predict ----\n",
    "    print(\"Predicting on test set...\")\n",
    "    y_pred = best_model.best_estimator_.predict(X_test)\n",
    "\n",
    "    # ---- 9.8 Metrics ----\n",
    "    metrics = compute_metrics(y_test, y_pred, labels=np.arange(len(label_names)))\n",
    "    print_metrics(metrics, label_names=label_names)\n",
    "    plot_confusion_matrix(metrics, label_names=label_names, normalize=True)\n",
    "\n",
    "    # ---- 9.9 Feature importance ----\n",
    "    imp_df = get_feature_importance(best_model, feature_names=feature_names)\n",
    "    print(\"\\nTop features:\")\n",
    "    print(imp_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e69067c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and extracting features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_4872\\1369356254.py:64: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  auc = np.trapz(sig)\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_4872\\1369356254.py:65: RuntimeWarning: invalid value encountered in log1p\n",
      "  log_mean = np.log1p(mean)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total segments: 2638, Features per segment: 62\n",
      "\n",
      "=== Leave-One-Subject-Out CV ===\n",
      "[Subject S008] Accuracy: 0.658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.72      0.52      0.60        60\n",
      "    med_pain       0.62      0.80      0.70        60\n",
      "\n",
      "    accuracy                           0.66       120\n",
      "   macro avg       0.67      0.66      0.65       120\n",
      "weighted avg       0.67      0.66      0.65       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31 29]\n",
      " [12 48]]\n",
      "[Subject S009] Accuracy: 0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.51      0.59      0.55        59\n",
      "    med_pain       0.52      0.43      0.47        60\n",
      "\n",
      "    accuracy                           0.51       119\n",
      "   macro avg       0.51      0.51      0.51       119\n",
      "weighted avg       0.51      0.51      0.51       119\n",
      "\n",
      "Confusion Matrix:\n",
      "[[35 24]\n",
      " [34 26]]\n",
      "[Subject S019] Accuracy: 0.500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.50      0.72      0.59        60\n",
      "    med_pain       0.50      0.28      0.36        60\n",
      "\n",
      "    accuracy                           0.50       120\n",
      "   macro avg       0.50      0.50      0.48       120\n",
      "weighted avg       0.50      0.50      0.48       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[43 17]\n",
      " [43 17]]\n",
      "[Subject S026] Accuracy: 0.475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.48      0.73      0.58        60\n",
      "    med_pain       0.45      0.22      0.29        60\n",
      "\n",
      "    accuracy                           0.47       120\n",
      "   macro avg       0.47      0.47      0.44       120\n",
      "weighted avg       0.47      0.47      0.44       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[44 16]\n",
      " [47 13]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Subject S034] Accuracy: 0.575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.60      0.43      0.50        60\n",
      "    med_pain       0.56      0.72      0.63        60\n",
      "\n",
      "    accuracy                           0.57       120\n",
      "   macro avg       0.58      0.57      0.57       120\n",
      "weighted avg       0.58      0.57      0.57       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26 34]\n",
      " [17 43]]\n",
      "[Subject S045] Accuracy: 0.617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.60      0.72      0.65        60\n",
      "    med_pain       0.65      0.52      0.57        60\n",
      "\n",
      "    accuracy                           0.62       120\n",
      "   macro avg       0.62      0.62      0.61       120\n",
      "weighted avg       0.62      0.62      0.61       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[43 17]\n",
      " [29 31]]\n",
      "[Subject S049] Accuracy: 0.533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.52      0.77      0.62        60\n",
      "    med_pain       0.56      0.30      0.39        60\n",
      "\n",
      "    accuracy                           0.53       120\n",
      "   macro avg       0.54      0.53      0.51       120\n",
      "weighted avg       0.54      0.53      0.51       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[46 14]\n",
      " [42 18]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Subject S051] Accuracy: 0.533\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.53      0.53      0.53        60\n",
      "    med_pain       0.53      0.53      0.53        60\n",
      "\n",
      "    accuracy                           0.53       120\n",
      "   macro avg       0.53      0.53      0.53       120\n",
      "weighted avg       0.53      0.53      0.53       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[32 28]\n",
      " [28 32]]\n",
      "[Subject S052] Accuracy: 0.475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.48      0.65      0.55        60\n",
      "    med_pain       0.46      0.30      0.36        60\n",
      "\n",
      "    accuracy                           0.47       120\n",
      "   macro avg       0.47      0.47      0.46       120\n",
      "weighted avg       0.47      0.47      0.46       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[39 21]\n",
      " [42 18]]\n",
      "[Subject S057] Accuracy: 0.508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.52      0.23      0.32        60\n",
      "    med_pain       0.51      0.78      0.61        60\n",
      "\n",
      "    accuracy                           0.51       120\n",
      "   macro avg       0.51      0.51      0.47       120\n",
      "weighted avg       0.51      0.51      0.47       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14 46]\n",
      " [13 47]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Subject S068] Accuracy: 0.462\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.46      0.44      0.45        59\n",
      "    med_pain       0.47      0.48      0.48        60\n",
      "\n",
      "    accuracy                           0.46       119\n",
      "   macro avg       0.46      0.46      0.46       119\n",
      "weighted avg       0.46      0.46      0.46       119\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26 33]\n",
      " [31 29]]\n",
      "[Subject S069] Accuracy: 0.508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.51      0.55      0.53        60\n",
      "    med_pain       0.51      0.47      0.49        60\n",
      "\n",
      "    accuracy                           0.51       120\n",
      "   macro avg       0.51      0.51      0.51       120\n",
      "weighted avg       0.51      0.51      0.51       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[33 27]\n",
      " [32 28]]\n",
      "[Subject S070] Accuracy: 0.517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.52      0.45      0.48        60\n",
      "    med_pain       0.51      0.58      0.55        60\n",
      "\n",
      "    accuracy                           0.52       120\n",
      "   macro avg       0.52      0.52      0.51       120\n",
      "weighted avg       0.52      0.52      0.51       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27 33]\n",
      " [25 35]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Subject S072] Accuracy: 0.400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.43      0.63      0.51        60\n",
      "    med_pain       0.31      0.17      0.22        60\n",
      "\n",
      "    accuracy                           0.40       120\n",
      "   macro avg       0.37      0.40      0.37       120\n",
      "weighted avg       0.37      0.40      0.37       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[38 22]\n",
      " [50 10]]\n",
      "[Subject S076] Accuracy: 0.508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.53      0.13      0.21        60\n",
      "    med_pain       0.50      0.88      0.64        60\n",
      "\n",
      "    accuracy                           0.51       120\n",
      "   macro avg       0.52      0.51      0.43       120\n",
      "weighted avg       0.52      0.51      0.43       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 8 52]\n",
      " [ 7 53]]\n",
      "[Subject S087] Accuracy: 0.483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.48      0.52      0.50        60\n",
      "    med_pain       0.48      0.45      0.47        60\n",
      "\n",
      "    accuracy                           0.48       120\n",
      "   macro avg       0.48      0.48      0.48       120\n",
      "weighted avg       0.48      0.48      0.48       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31 29]\n",
      " [33 27]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Subject S095] Accuracy: 0.567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.55      0.78      0.64        60\n",
      "    med_pain       0.62      0.35      0.45        60\n",
      "\n",
      "    accuracy                           0.57       120\n",
      "   macro avg       0.58      0.57      0.55       120\n",
      "weighted avg       0.58      0.57      0.55       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[47 13]\n",
      " [39 21]]\n",
      "[Subject S107] Accuracy: 0.583\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.56      0.75      0.64        60\n",
      "    med_pain       0.62      0.42      0.50        60\n",
      "\n",
      "    accuracy                           0.58       120\n",
      "   macro avg       0.59      0.58      0.57       120\n",
      "weighted avg       0.59      0.58      0.57       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[45 15]\n",
      " [35 25]]\n",
      "[Subject S110] Accuracy: 0.483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.48      0.43      0.46        60\n",
      "    med_pain       0.48      0.53      0.51        60\n",
      "\n",
      "    accuracy                           0.48       120\n",
      "   macro avg       0.48      0.48      0.48       120\n",
      "weighted avg       0.48      0.48      0.48       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[26 34]\n",
      " [28 32]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Subject S114] Accuracy: 0.617\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.62      0.62      0.62        60\n",
      "    med_pain       0.62      0.62      0.62        60\n",
      "\n",
      "    accuracy                           0.62       120\n",
      "   macro avg       0.62      0.62      0.62       120\n",
      "weighted avg       0.62      0.62      0.62       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37 23]\n",
      " [23 37]]\n",
      "[Subject S126] Accuracy: 0.500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.50      0.45      0.47        60\n",
      "    med_pain       0.50      0.55      0.52        60\n",
      "\n",
      "    accuracy                           0.50       120\n",
      "   macro avg       0.50      0.50      0.50       120\n",
      "weighted avg       0.50      0.50      0.50       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27 33]\n",
      " [27 33]]\n",
      "[Subject S134] Accuracy: 0.475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    low_pain       0.48      0.63      0.55        60\n",
      "    med_pain       0.46      0.32      0.38        60\n",
      "\n",
      "    accuracy                           0.47       120\n",
      "   macro avg       0.47      0.47      0.46       120\n",
      "weighted avg       0.47      0.47      0.46       120\n",
      "\n",
      "Confusion Matrix:\n",
      "[[38 22]\n",
      " [41 19]]\n",
      "\n",
      "LOSO Mean Accuracy: 0.522\n",
      "\n",
      "Top 10 Features (importance):\n",
      "Feature 8: 0.0337\n",
      "Feature 4: 0.0323\n",
      "Feature 15: 0.0271\n",
      "Feature 12: 0.0246\n",
      "Feature 59: 0.0245\n",
      "Feature 30: 0.0240\n",
      "Feature 32: 0.0235\n",
      "Feature 20: 0.0232\n",
      "Feature 48: 0.0226\n",
      "Feature 3: 0.0226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [16:02:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy.signal import butter, filtfilt, iirnotch, resample\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- 1. Signal Filtering Utilities ---\n",
    "\n",
    "def bandpass_filter(data, fs, lowcut, highcut, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low, high = lowcut/nyq, highcut/nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "def notch_filter(data, fs, freq=50.0, Q=30):\n",
    "    nyq = 0.5 * fs\n",
    "    w0 = freq / nyq\n",
    "    b, a = iirnotch(w0, Q)\n",
    "    return filtfilt(b, a, data, axis=0)\n",
    "\n",
    "def preprocess_channel(signal, fs, kind):\n",
    "    # Filtering params per channel type\n",
    "    if kind == 'EMG':\n",
    "        sig = bandpass_filter(signal, fs, 20, 450)\n",
    "        sig = notch_filter(sig, fs, 50) # Remove powerline\n",
    "    elif kind == 'ECG':\n",
    "        sig = bandpass_filter(signal, fs, 0.5, 50)\n",
    "        sig = notch_filter(sig, fs, 50)\n",
    "    elif kind == 'SCL':\n",
    "        sig = bandpass_filter(signal, fs, 0.05, 5)\n",
    "    else:\n",
    "        sig = signal\n",
    "    # Downsample to 250Hz for all\n",
    "    factor = int(fs/250)\n",
    "    if factor > 1:\n",
    "        sig = resample(sig, int(len(sig)//factor))\n",
    "    return sig\n",
    "\n",
    "def wavelet_denoise(sig, wavelet='db4', level=2):\n",
    "    coeffs = pywt.wavedec(sig, wavelet, level=level)\n",
    "    sigma = np.median(np.abs(coeffs[-level])) / 0.6745\n",
    "    uthresh = sigma * np.sqrt(2*np.log(len(sig)))\n",
    "    denoised_coeffs = [coeffs[0]] + [pywt.threshold(c, value=uthresh, mode='soft') for c in coeffs[1:]]\n",
    "    return pywt.waverec(denoised_coeffs, wavelet)[:len(sig)]\n",
    "\n",
    "# --- 2. Feature Extraction ---\n",
    "def emg_features(sig):\n",
    "    # RMS, log RMS, STD, waveform length, ZCR\n",
    "    rms = np.sqrt(np.mean(sig**2))\n",
    "    log_rms = np.log1p(rms)\n",
    "    std = np.std(sig)\n",
    "    wl = np.sum(np.abs(np.diff(sig)))\n",
    "    zcr = ((sig[:-1]*sig[1:])<0).sum() / len(sig)\n",
    "    return [rms, log_rms, std, wl, zcr]\n",
    "\n",
    "def scl_features(sig, fs):\n",
    "    mean = np.mean(sig)\n",
    "    slope = (sig[-1]-sig[0])/len(sig)\n",
    "    auc = np.trapz(sig)\n",
    "    log_mean = np.log1p(mean)\n",
    "    # SCRs: count upward jumps > 0.01uS in 1s\n",
    "    diff = np.diff(sig)\n",
    "    scrs = ((diff > 0.01).astype(int)).sum()\n",
    "    scr_amp = diff[diff > 0.01].mean() if np.any(diff > 0.01) else 0\n",
    "    return [mean, scrs, scr_amp, slope, auc, log_mean]\n",
    "\n",
    "def ecg_features(sig, fs):\n",
    "    # Simple peak detection for R-peaks (for demonstration)\n",
    "    from scipy.signal import find_peaks\n",
    "    peaks, _ = find_peaks(sig, distance=fs*0.5)  # ~> 60 bpm\n",
    "    rr_intervals = np.diff(peaks)/fs if len(peaks) > 1 else np.array([0])\n",
    "    hr = 60/rr_intervals.mean() if rr_intervals.mean() > 0 else 0\n",
    "    rmssd = np.sqrt(np.mean(np.square(np.diff(rr_intervals)))) if len(rr_intervals) > 1 else 0\n",
    "    sdnn = rr_intervals.std() if len(rr_intervals) > 1 else 0\n",
    "    # Frequency domain (simple, not full Welch)\n",
    "    freqs, psd = np.fft.rfftfreq(len(sig), 1/fs), np.abs(np.fft.rfft(sig))**2\n",
    "    lf_band = (freqs >= 0.04) & (freqs < 0.15)\n",
    "    hf_band = (freqs >= 0.15) & (freqs < 0.4)\n",
    "    lf = psd[lf_band].sum()\n",
    "    hf = psd[hf_band].sum()\n",
    "    lf_hf = np.log1p(lf/hf) if hf > 0 else 0\n",
    "    return [hr, rmssd, sdnn, lf, hf, lf_hf]\n",
    "\n",
    "def wavelet_energy(sig, wavelet='db4', level=3):\n",
    "    coeffs = pywt.wavedec(sig, wavelet, level=level)\n",
    "    energies = [np.sum(np.square(c)) for c in coeffs]\n",
    "    entropy = -np.sum([e/np.sum(energies)*np.log(e/np.sum(energies)+1e-8) for e in energies])\n",
    "    return energies + [entropy, np.mean(sig), np.std(sig)]\n",
    "\n",
    "def extract_segment_features(data, fs, ch_names):\n",
    "    # EMG: ch 0,1,2; SCL: ch3; ECG: ch4\n",
    "    feats = []\n",
    "    for idx, kind in enumerate(['EMG','EMG','EMG','SCL','ECG']):\n",
    "        sig = data[:, idx]\n",
    "        # Preprocess, denoise\n",
    "        sig = preprocess_channel(sig, fs, kind)\n",
    "        sig = wavelet_denoise(sig)\n",
    "        # Feature extraction\n",
    "        if kind == 'EMG':\n",
    "            feats.extend(emg_features(sig))\n",
    "            feats.extend(wavelet_energy(sig))\n",
    "        elif kind == 'SCL':\n",
    "            feats.extend(scl_features(sig, 250))\n",
    "            feats.extend(wavelet_energy(sig))\n",
    "        elif kind == 'ECG':\n",
    "            feats.extend(ecg_features(sig, 250))\n",
    "            feats.extend(wavelet_energy(sig))\n",
    "    return feats\n",
    "\n",
    "# --- 3. Dataset Loader ---\n",
    "def collect_segments(root_dir):\n",
    "    segments = []\n",
    "    labels = []\n",
    "    subjects = []\n",
    "    pain_map = {}\n",
    "    for pain_label in sorted(os.listdir(root_dir)):\n",
    "        pain_path = os.path.join(root_dir, pain_label)\n",
    "        if not os.path.isdir(pain_path): continue\n",
    "        for subj in sorted(os.listdir(pain_path)):\n",
    "            subj_path = os.path.join(pain_path, subj)\n",
    "            if not os.path.isdir(subj_path): continue\n",
    "            for segfile in sorted(os.listdir(subj_path)):\n",
    "                if not segfile.endswith('.mat'): continue\n",
    "                matf = os.path.join(subj_path, segfile)\n",
    "                try:\n",
    "                    mat = scipy.io.loadmat(matf)\n",
    "                    data = mat['data']  # (10000,5)\n",
    "                    fs = int(mat['fs'].ravel()[0])\n",
    "                    ch_names = [str(s[0]) if isinstance(s, np.ndarray) else str(s) for s in mat['labels'].ravel()]\n",
    "                    feats = extract_segment_features(data, fs, ch_names)\n",
    "                    segments.append(feats)\n",
    "                    labels.append(pain_label)\n",
    "                    subjects.append(subj)\n",
    "                    pain_map[pain_label] = pain_map.get(pain_label, len(pain_map))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with {matf}: {e}\")\n",
    "    return np.array(segments), np.array(labels), np.array(subjects), pain_map\n",
    "\n",
    "# --- 4. LOSO Cross-Validation ---\n",
    "def loso_cv(X, y, subjects):\n",
    "    unique_subjects = np.unique(subjects)\n",
    "    for subj in unique_subjects:\n",
    "        test_idx = (subjects == subj)\n",
    "        train_idx = ~test_idx\n",
    "        yield X[train_idx], X[test_idx], y[train_idx], y[test_idx], subj\n",
    "\n",
    "# --- 5. Main Pipeline ---\n",
    "if __name__ == \"__main__\":\n",
    "    root_dir = r\"D:\\bio_s\"  # <<< CHANGE if needed\n",
    "    print(\"Loading and extracting features...\")\n",
    "    X, y, subjects, pain_map = collect_segments(root_dir)\n",
    "    print(f\"Total segments: {len(X)}, Features per segment: {X.shape[1]}\")\n",
    "\n",
    "    # Encode labels as integers\n",
    "    label_names = sorted(pain_map, key=lambda k: pain_map[k])\n",
    "    y_enc = np.array([pain_map[lab] for lab in y])\n",
    "\n",
    "    # Per-segment z-score normalization (robust to subject)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # LOSO CV\n",
    "    accs = []\n",
    "    print(\"\\n=== Leave-One-Subject-Out CV ===\")\n",
    "    for Xtr, Xte, ytr, yte, subj in loso_cv(X, y_enc, subjects):\n",
    "        model = XGBClassifier(n_estimators=100, max_depth=4, eval_metric='mlogloss', use_label_encoder=False, random_state=42)\n",
    "        model.fit(Xtr, ytr)\n",
    "        ypred = model.predict(Xte)\n",
    "        acc = accuracy_score(yte, ypred)\n",
    "        accs.append(acc)\n",
    "        print(f\"[Subject {subj}] Accuracy: {acc:.3f}\")\n",
    "        print(classification_report(yte, ypred, target_names=label_names))\n",
    "        print(\"Confusion Matrix:\")\n",
    "        print(confusion_matrix(yte, ypred))\n",
    "        # Feature importance (mean of last fold)\n",
    "        importances = model.feature_importances_\n",
    "    print(f\"\\nLOSO Mean Accuracy: {np.mean(accs):.3f}\")\n",
    "\n",
    "    # Show top features (for last fold)\n",
    "    top_idx = np.argsort(importances)[::-1][:10]\n",
    "    print(\"\\nTop 10 Features (importance):\")\n",
    "    for idx in top_idx:\n",
    "        print(f\"Feature {idx}: {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fada2f20",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_deprecate_Xt_in_inverse_transform' from 'sklearn.utils.deprecation' (c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, StratifiedKFold, GridSearchCV\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# --- Advanced Feature Engineering ---\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\__init__.py:52\u001b[0m\n\u001b[0;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     53\u001b[0m         combine,\n\u001b[0;32m     54\u001b[0m         ensemble,\n\u001b[0;32m     55\u001b[0m         exceptions,\n\u001b[0;32m     56\u001b[0m         metrics,\n\u001b[0;32m     57\u001b[0m         over_sampling,\n\u001b[0;32m     58\u001b[0m         pipeline,\n\u001b[0;32m     59\u001b[0m         tensorflow,\n\u001b[0;32m     60\u001b[0m         under_sampling,\n\u001b[0;32m     61\u001b[0m         utils,\n\u001b[0;32m     62\u001b[0m     )\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[0;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\base.py:15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m METHODS\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _fit_context, get_tags, validate_data\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\__init__.py:6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`imblearn.utils` module includes various utilities.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstring\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Substitution\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     check_neighbors_object,\n\u001b[0;32m      8\u001b[0m     check_sampling_strategy,\n\u001b[0;32m      9\u001b[0m     check_target_type,\n\u001b[0;32m     10\u001b[0m )\n\u001b[0;32m     12\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_neighbors_object\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_sampling_strategy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheck_target_type\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSubstitution\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     17\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\_validation.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _num_samples\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_pandas_df, check_array\n\u001b[0;32m     22\u001b[0m SAMPLING_KIND \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mover-sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munder-sampling\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbypass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m )\n\u001b[0;32m     29\u001b[0m TARGET_KIND \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imblearn\\utils\\_sklearn_compat.py:815\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_dataclass_args())\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mTags\u001b[39;00m(Tags):\n\u001b[0;32m    813\u001b[0m     sampler_tags: SamplerTags \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 815\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_test_common\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minstance_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    816\u001b[0m     _construct_instances,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m    817\u001b[0m )\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator_checks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    819\u001b[0m     check_estimator,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m    820\u001b[0m     parametrize_with_checks,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m    821\u001b[0m )\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_test_common\\instance_generator.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone, config_context\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalibration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CalibratedClassifierCV\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     HDBSCAN,\n\u001b[0;32m     15\u001b[0m     AffinityPropagation,\n\u001b[0;32m     16\u001b[0m     AgglomerativeClustering,\n\u001b[0;32m     17\u001b[0m     Birch,\n\u001b[0;32m     18\u001b[0m     BisectingKMeans,\n\u001b[0;32m     19\u001b[0m     FeatureAgglomeration,\n\u001b[0;32m     20\u001b[0m     KMeans,\n\u001b[0;32m     21\u001b[0m     MeanShift,\n\u001b[0;32m     22\u001b[0m     MiniBatchKMeans,\n\u001b[0;32m     23\u001b[0m     SpectralBiclustering,\n\u001b[0;32m     24\u001b[0m     SpectralClustering,\n\u001b[0;32m     25\u001b[0m     SpectralCoclustering,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompose\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ColumnTransformer\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcovariance\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GraphicalLasso, GraphicalLassoCV\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\__init__.py:7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Authors: The scikit-learn developers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# SPDX-License-Identifier: BSD-3-Clause\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_affinity_propagation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AffinityPropagation, affinity_propagation\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_agglomerative\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     AgglomerativeClustering,\n\u001b[0;32m      9\u001b[0m     FeatureAgglomeration,\n\u001b[0;32m     10\u001b[0m     linkage_tree,\n\u001b[0;32m     11\u001b[0m     ward_tree,\n\u001b[0;32m     12\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bicluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SpectralBiclustering, SpectralCoclustering\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_birch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Birch\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_agglomerative.py:44\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# mypy error: Module 'sklearn.cluster' has no attribute '_hierarchical_fast'\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _hierarchical_fast \u001b[38;5;28;01mas\u001b[39;00m _hierarchical  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_feature_agglomeration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgglomerationTransform\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# For non fully-connected graphs\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_fix_connectivity\u001b[39m(X, connectivity, affinity):\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_feature_agglomeration.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TransformerMixin\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _deprecate_Xt_in_inverse_transform\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_is_fitted, validate_data\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Mixin class for feature agglomeration.\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_deprecate_Xt_in_inverse_transform' from 'sklearn.utils.deprecation' (c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy.signal import butter, filtfilt, iirnotch, resample\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report, f1_score\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Advanced Feature Engineering ---\n",
    "def extract_advanced_features(data, fs, ch_names):\n",
    "    feats = []\n",
    "    # Per-channel features\n",
    "    for idx, kind in enumerate(['EMG','EMG','EMG','SCL','ECG']):\n",
    "        sig = data[:, idx]\n",
    "        # Filtering and denoising\n",
    "        if kind == 'EMG':\n",
    "            sig = bandpass_filter(sig, fs, 20, 450)\n",
    "            sig = notch_filter(sig, fs, 50)\n",
    "        elif kind == 'ECG':\n",
    "            sig = bandpass_filter(sig, fs, 0.5, 50)\n",
    "            sig = notch_filter(sig, fs, 50)\n",
    "        elif kind == 'SCL':\n",
    "            sig = bandpass_filter(sig, fs, 0.05, 5)\n",
    "        sig = resample(sig, int(len(sig)//(fs/250))) if fs > 250 else sig\n",
    "        sig = wavelet_denoise(sig)\n",
    "        # Time-domain\n",
    "        feats.extend([\n",
    "            np.mean(sig), np.std(sig), np.max(sig), np.min(sig),\n",
    "            skew(sig), kurtosis(sig)\n",
    "        ])\n",
    "        # Frequency-domain\n",
    "        freqs = np.fft.rfftfreq(len(sig), 1/250)\n",
    "        psd = np.abs(np.fft.rfft(sig))**2\n",
    "        feats.append(np.sum(psd[(freqs>=0.5)&(freqs<4)]))  # Delta\n",
    "        feats.append(np.sum(psd[(freqs>=4)&(freqs<8)]))    # Theta\n",
    "        feats.append(np.sum(psd[(freqs>=8)&(freqs<13)]))   # Alpha\n",
    "        feats.append(np.sum(psd[(freqs>=13)&(freqs<30)]))  # Beta\n",
    "        feats.append(np.sum(psd[(freqs>=30)&(freqs<45)]))  # Gamma\n",
    "        # Wavelet energy/entropy\n",
    "        coeffs = pywt.wavedec(sig, 'db4', level=3)\n",
    "        energies = [np.sum(np.square(c)) for c in coeffs]\n",
    "        total_energy = np.sum(energies)\n",
    "        entropy = -np.sum([(e/total_energy)*np.log(e/total_energy+1e-8) if e>0 else 0 for e in energies])\n",
    "        feats.extend(energies + [entropy])\n",
    "    # Cross-channel features (correlations)\n",
    "    for i in range(data.shape[1]):\n",
    "        for j in range(i+1, data.shape[1]):\n",
    "            feats.append(np.corrcoef(data[:,i], data[:,j])[0,1])\n",
    "    # Delta features (change from start to end)\n",
    "    for idx in range(data.shape[1]):\n",
    "        sig = data[:, idx]\n",
    "        feats.append(sig[-1] - sig[0])\n",
    "    return np.nan_to_num(feats)\n",
    "\n",
    "# --- Data Loader ---\n",
    "def collect_segments_advanced(root_dir):\n",
    "    segments, labels, subjects, pain_map = [], [], [], {}\n",
    "    for pain_label in sorted(os.listdir(root_dir)):\n",
    "        pain_path = os.path.join(root_dir, pain_label)\n",
    "        if not os.path.isdir(pain_path): continue\n",
    "        for subj in sorted(os.listdir(pain_path)):\n",
    "            subj_path = os.path.join(pain_path, subj)\n",
    "            if not os.path.isdir(subj_path): continue\n",
    "            for segfile in sorted(os.listdir(subj_path)):\n",
    "                if not segfile.endswith('.mat'): continue\n",
    "                matf = os.path.join(subj_path, segfile)\n",
    "                try:\n",
    "                    mat = scipy.io.loadmat(matf)\n",
    "                    data = mat['data']\n",
    "                    fs = int(mat['fs'].ravel()[0])\n",
    "                    ch_names = [str(s[0]) if isinstance(s, np.ndarray) else str(s) for s in mat['labels'].ravel()]\n",
    "                    feats = extract_advanced_features(data, fs, ch_names)\n",
    "                    segments.append(feats)\n",
    "                    labels.append(pain_label)\n",
    "                    subjects.append(subj)\n",
    "                    pain_map[pain_label] = pain_map.get(pain_label, len(pain_map))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with {matf}: {e}\")\n",
    "    return np.array(segments), np.array(labels), np.array(subjects), pain_map\n",
    "\n",
    "# --- Main Pipeline ---\n",
    "root_dir = r\"D:\\bio_s\"  # Change if needed\n",
    "print(\"Loading and extracting advanced features...\")\n",
    "X, y, subjects, pain_map = collect_segments_advanced(root_dir)\n",
    "print(f\"Total segments: {len(X)}, Features per segment: {X.shape[1]}\")\n",
    "label_names = sorted(pain_map, key=lambda k: pain_map[k])\n",
    "y_enc = np.array([pain_map[lab] for lab in y])\n",
    "\n",
    "# Per-segment z-score normalization\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# --- Class Balancing ---\n",
    "sm = SMOTE(random_state=42)\n",
    "X_bal, y_bal = sm.fit_resample(X, y_enc)\n",
    "\n",
    "# --- Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.3, stratify=y_bal, random_state=42)\n",
    "\n",
    "# --- Ensemble Model ---\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=8, class_weight='balanced', random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=6, eval_metric='mlogloss', use_label_encoder=False, random_state=42)\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('xgb', xgb)], voting='soft', n_jobs=-1)\n",
    "\n",
    "# --- Hyperparameter Tuning ---\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [100, 200],\n",
    "    'xgb__n_estimators': [100, 200],\n",
    "    'rf__max_depth': [6, 8],\n",
    "    'xgb__max_depth': [4, 6],\n",
    "}\n",
    "grid = GridSearchCV(ensemble, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluation ---\n",
    "y_pred = grid.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {acc:.3f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# --- LOSO CV for Robustness ---\n",
    "accs = []\n",
    "all_true = []\n",
    "all_pred = []\n",
    "for subj in np.unique(subjects):\n",
    "    test_idx = (subjects == subj)\n",
    "    train_idx = ~test_idx\n",
    "    if np.sum(test_idx) == 0 or np.sum(train_idx) == 0:\n",
    "        continue\n",
    "    Xtr, Xte = X[train_idx], X[test_idx]\n",
    "    ytr, yte = y_enc[train_idx], y_enc[test_idx]\n",
    "    Xtr_bal, ytr_bal = sm.fit_resample(Xtr, ytr)\n",
    "    model = grid.best_estimator_\n",
    "    model.fit(Xtr_bal, ytr_bal)\n",
    "    ypred = model.predict(Xte)\n",
    "    accs.append(accuracy_score(yte, ypred))\n",
    "    all_true.extend(yte)\n",
    "    all_pred.extend(ypred)\n",
    "print(f\"\\nLOSO Mean Accuracy: {np.mean(accs):.3f}\")\n",
    "print(\"\\nLOSO Classification Report:\")\n",
    "print(classification_report(all_true, all_pred, target_names=label_names))\n",
    "print(\"LOSO Confusion Matrix:\")\n",
    "print(confusion_matrix(all_true, all_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b1fa39",
   "metadata": {},
   "source": [
    "# Advanced Pipeline for Improved Pain Intensity Prediction\n",
    "This cell implements advanced feature engineering, ensemble modeling, and robust evaluation (train/test split and LOSO CV) to target 80%+ accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b71404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from scipy.signal import butter, filtfilt, iirnotch, resample\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pywt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Advanced Feature Engineering ---\n",
    "def extract_advanced_features(data, fs, ch_names):\n",
    "    feats = []\n",
    "    # Per-channel features\n",
    "    for idx, kind in enumerate(['EMG','EMG','EMG','SCL','ECG']):\n",
    "        sig = data[:, idx]\n",
    "        # Filtering and denoising\n",
    "        if kind == 'EMG':\n",
    "            sig = bandpass_filter(sig, fs, 20, 450)\n",
    "            sig = notch_filter(sig, fs, 50)\n",
    "        elif kind == 'ECG':\n",
    "            sig = bandpass_filter(sig, fs, 0.5, 50)\n",
    "            sig = notch_filter(sig, fs, 50)\n",
    "        elif kind == 'SCL':\n",
    "            sig = bandpass_filter(sig, fs, 0.05, 5)\n",
    "        sig = resample(sig, int(len(sig)//(fs/250))) if fs > 250 else sig\n",
    "        sig = wavelet_denoise(sig)\n",
    "        # Time-domain\n",
    "        feats.extend([\n",
    "            np.mean(sig), np.std(sig), np.max(sig), np.min(sig),\n",
    "            skew(sig), kurtosis(sig)\n",
    "        ])\n",
    "        # Frequency-domain\n",
    "        freqs = np.fft.rfftfreq(len(sig), 1/250)\n",
    "        psd = np.abs(np.fft.rfft(sig))**2\n",
    "        feats.append(np.sum(psd[(freqs>=0.5)&(freqs<4)]))  # Delta\n",
    "        feats.append(np.sum(psd[(freqs>=4)&(freqs<8)]))    # Theta\n",
    "        feats.append(np.sum(psd[(freqs>=8)&(freqs<13)]))   # Alpha\n",
    "        feats.append(np.sum(psd[(freqs>=13)&(freqs<30)]))  # Beta\n",
    "        feats.append(np.sum(psd[(freqs>=30)&(freqs<45)]))  # Gamma\n",
    "        # Wavelet energy/entropy\n",
    "        coeffs = pywt.wavedec(sig, 'db4', level=3)\n",
    "        energies = [np.sum(np.square(c)) for c in coeffs]\n",
    "        total_energy = np.sum(energies)\n",
    "        entropy = -np.sum([(e/total_energy)*np.log(e/total_energy+1e-8) if e>0 else 0 for e in energies])\n",
    "        feats.extend(energies + [entropy])\n",
    "    # Cross-channel features (correlations)\n",
    "    for i in range(data.shape[1]):\n",
    "        for j in range(i+1, data.shape[1]):\n",
    "            feats.append(np.corrcoef(data[:,i], data[:,j])[0,1])\n",
    "    # Delta features (change from start to end)\n",
    "    for idx in range(data.shape[1]):\n",
    "        sig = data[:, idx]\n",
    "        feats.append(sig[-1] - sig[0])\n",
    "    return np.nan_to_num(feats)\n",
    "\n",
    "# --- Data Loader ---\n",
    "def collect_segments_advanced(root_dir):\n",
    "    segments, labels, subjects, pain_map = [], [], [], {}\n",
    "    for pain_label in sorted(os.listdir(root_dir)):\n",
    "        pain_path = os.path.join(root_dir, pain_label)\n",
    "        if not os.path.isdir(pain_path): continue\n",
    "        for subj in sorted(os.listdir(pain_path)):\n",
    "            subj_path = os.path.join(pain_path, subj)\n",
    "            if not os.path.isdir(subj_path): continue\n",
    "            for segfile in sorted(os.listdir(subj_path)):\n",
    "                if not segfile.endswith('.mat'): continue\n",
    "                matf = os.path.join(subj_path, segfile)\n",
    "                try:\n",
    "                    mat = scipy.io.loadmat(matf)\n",
    "                    data = mat['data']\n",
    "                    fs = int(mat['fs'].ravel()[0])\n",
    "                    ch_names = [str(s[0]) if isinstance(s, np.ndarray) else str(s) for s in mat['labels'].ravel()]\n",
    "                    feats = extract_advanced_features(data, fs, ch_names)\n",
    "                    segments.append(feats)\n",
    "                    labels.append(pain_label)\n",
    "                    subjects.append(subj)\n",
    "                    pain_map[pain_label] = pain_map.get(pain_label, len(pain_map))\n",
    "                except Exception as e:\n",
    "                    print(f\"Error with {matf}: {e}\")\n",
    "    return np.array(segments), np.array(labels), np.array(subjects), pain_map\n",
    "\n",
    "# --- Main Pipeline ---\n",
    "root_dir = r\"D:\\bio_s\"  # Change if needed\n",
    "print(\"Loading and extracting advanced features...\")\n",
    "X, y, subjects, pain_map = collect_segments_advanced(root_dir)\n",
    "print(f\"Total segments: {len(X)}, Features per segment: {X.shape[1]}\")\n",
    "label_names = sorted(pain_map, key=lambda k: pain_map[k])\n",
    "y_enc = np.array([pain_map[lab] for lab in y])\n",
    "\n",
    "# Per-segment z-score normalization\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# --- Class Balancing ---\n",
    "sm = SMOTE(random_state=42)\n",
    "X_bal, y_bal = sm.fit_resample(X, y_enc)\n",
    "\n",
    "# --- Train/Test Split ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.3, stratify=y_bal, random_state=42)\n",
    "\n",
    "# --- Ensemble Model ---\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=8, class_weight='balanced', random_state=42)\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=6, eval_metric='mlogloss', use_label_encoder=False, random_state=42)\n",
    "ensemble = VotingClassifier(estimators=[('rf', rf), ('xgb', xgb)], voting='soft', n_jobs=-1)\n",
    "\n",
    "# --- Hyperparameter Tuning ---\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [100, 200],\n",
    "    'xgb__n_estimators': [100, 200],\n",
    "    'rf__max_depth': [6, 8],\n",
    "    'xgb__max_depth': [4, 6],\n",
    "}\n",
    "grid = GridSearchCV(ensemble, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# --- Evaluation ---\n",
    "y_pred = grid.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {acc:.3f}\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_names))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# --- LOSO CV for Robustness ---\n",
    "accs = []\n",
    "all_true = []\n",
    "all_pred = []\n",
    "for subj in np.unique(subjects):\n",
    "    test_idx = (subjects == subj)\n",
    "    train_idx = ~test_idx\n",
    "    if np.sum(test_idx) == 0 or np.sum(train_idx) == 0:\n",
    "        continue\n",
    "    Xtr, Xte = X[train_idx], X[test_idx]\n",
    "    ytr, yte = y_enc[train_idx], y_enc[test_idx]\n",
    "    Xtr_bal, ytr_bal = sm.fit_resample(Xtr, ytr)\n",
    "    model = grid.best_estimator_\n",
    "    model.fit(Xtr_bal, ytr_bal)\n",
    "    ypred = model.predict(Xte)\n",
    "    accs.append(accuracy_score(yte, ypred))\n",
    "    all_true.extend(yte)\n",
    "    all_pred.extend(ypred)\n",
    "print(f\"\\nLOSO Mean Accuracy: {np.mean(accs):.3f}\")\n",
    "print(\"\\nLOSO Classification Report:\")\n",
    "print(classification_report(all_true, all_pred, target_names=label_names))\n",
    "print(\"LOSO Confusion Matrix:\")\n",
    "print(confusion_matrix(all_true, all_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6541d6d4",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "- This pipeline uses advanced features, class balancing, ensemble models, and both train/test and LOSO CV.\n",
    "- Review the printed accuracy and reports. Tune the feature set or model parameters further if needed to reach your 80% target."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
