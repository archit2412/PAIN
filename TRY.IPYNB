{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7be70b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "from scipy.signal import butter, filtfilt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data directory and parameters\n",
    "DATA_ROOT = r'D:\\bio_s'\n",
    "PAIN_LEVELS = {'low_pain': 'PL_1', 'med_pain': 'PL_2'}\n",
    "EMG_LABELS = ['corrugator', 'zygomaticus']\n",
    "EMG_COLS = [0, 1]  # Use only first two (corrugator, zygomaticus)\n",
    "BANDPASS = (20, 450)\n",
    "FS = 1000  # Sampling rate\n",
    "ARTIFACT_THRESHOLD = 1000  # uV, adjust as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b9262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Helper Functions\n",
    "# ------------------------\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "import numpy as np\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    \"\"\"\n",
    "    Designs a Butterworth bandpass filter.\n",
    "    \"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def apply_bandpass(data, fs, lowcut=20, highcut=450):\n",
    "    \"\"\"\n",
    "    Applies a bandpass filter to the data.\n",
    "    \"\"\"\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs)\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def artifact_rejection(emg_signal, threshold=1000):\n",
    "    \"\"\"\n",
    "    Returns True if the signal contains amplitudes above the artifact threshold.\n",
    "    \"\"\"\n",
    "    return np.any(np.abs(emg_signal) > threshold)\n",
    "\n",
    "def extract_features(emg_signal, fs):\n",
    "    \"\"\"\n",
    "    Extracts time and frequency domain features from an EMG signal segment.\n",
    "    \"\"\"\n",
    "    feats = {}\n",
    "    feats['mean'] = np.mean(emg_signal)\n",
    "    feats['std'] = np.std(emg_signal)\n",
    "    feats['rms'] = np.sqrt(np.mean(emg_signal ** 2))\n",
    "    feats['max'] = np.max(emg_signal)\n",
    "    feats['min'] = np.min(emg_signal)\n",
    "    feats['median'] = np.median(emg_signal)\n",
    "    feats['abs_mean'] = np.mean(np.abs(emg_signal))\n",
    "    feats['zero_cross'] = ((emg_signal[:-1] * emg_signal[1:]) < 0).sum()\n",
    "    feats['waveform_length'] = np.sum(np.abs(np.diff(emg_signal)))\n",
    "    # Frequency-domain features\n",
    "    fft_vals = np.abs(np.fft.rfft(emg_signal))\n",
    "    fft_freq = np.fft.rfftfreq(len(emg_signal), 1/fs)\n",
    "    feats['mean_freq'] = np.sum(fft_freq * fft_vals) / np.sum(fft_vals)\n",
    "    median_freq_idx = np.where(np.cumsum(fft_vals) >= np.sum(fft_vals)/2)[0][0]\n",
    "    feats['median_freq'] = fft_freq[median_freq_idx]\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef7930a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing D:\\bio_s\\low_pain\\S008...\n",
      "Processing D:\\bio_s\\low_pain\\S009...\n",
      "Processing D:\\bio_s\\low_pain\\S012...\n",
      "Processing D:\\bio_s\\low_pain\\S019...\n",
      "Processing D:\\bio_s\\low_pain\\S026...\n",
      "Processing D:\\bio_s\\low_pain\\S034...\n",
      "Processing D:\\bio_s\\low_pain\\S036...\n",
      "Processing D:\\bio_s\\low_pain\\S045...\n",
      "Processing D:\\bio_s\\low_pain\\S049...\n",
      "Processing D:\\bio_s\\low_pain\\S051...\n",
      "Processing D:\\bio_s\\low_pain\\S052...\n",
      "Processing D:\\bio_s\\low_pain\\S057...\n",
      "Processing D:\\bio_s\\low_pain\\S068...\n",
      "Processing D:\\bio_s\\low_pain\\S069...\n",
      "Processing D:\\bio_s\\low_pain\\S070...\n",
      "Processing D:\\bio_s\\low_pain\\S072...\n",
      "Processing D:\\bio_s\\low_pain\\S076...\n",
      "Processing D:\\bio_s\\low_pain\\S082...\n",
      "Processing D:\\bio_s\\low_pain\\S087...\n",
      "Processing D:\\bio_s\\low_pain\\S095...\n",
      "Processing D:\\bio_s\\low_pain\\S107...\n",
      "Processing D:\\bio_s\\low_pain\\S110...\n",
      "Processing D:\\bio_s\\low_pain\\S114...\n",
      "Processing D:\\bio_s\\low_pain\\S126...\n",
      "Processing D:\\bio_s\\low_pain\\S129...\n",
      "Processing D:\\bio_s\\low_pain\\S134...\n",
      "Processing D:\\bio_s\\med_pain\\S008...\n",
      "Processing D:\\bio_s\\med_pain\\S009...\n",
      "Processing D:\\bio_s\\med_pain\\S012...\n",
      "Processing D:\\bio_s\\med_pain\\S019...\n",
      "Processing D:\\bio_s\\med_pain\\S026...\n",
      "Processing D:\\bio_s\\med_pain\\S034...\n",
      "Processing D:\\bio_s\\med_pain\\S036...\n",
      "Processing D:\\bio_s\\med_pain\\S045...\n",
      "Processing D:\\bio_s\\med_pain\\S049...\n",
      "Processing D:\\bio_s\\med_pain\\S051...\n",
      "Processing D:\\bio_s\\med_pain\\S052...\n",
      "Processing D:\\bio_s\\med_pain\\S057...\n",
      "Processing D:\\bio_s\\med_pain\\S068...\n",
      "Processing D:\\bio_s\\med_pain\\S069...\n",
      "Processing D:\\bio_s\\med_pain\\S070...\n",
      "Processing D:\\bio_s\\med_pain\\S072...\n",
      "Processing D:\\bio_s\\med_pain\\S076...\n",
      "Processing D:\\bio_s\\med_pain\\S082...\n",
      "Processing D:\\bio_s\\med_pain\\S087...\n",
      "Processing D:\\bio_s\\med_pain\\S095...\n",
      "Processing D:\\bio_s\\med_pain\\S107...\n",
      "Processing D:\\bio_s\\med_pain\\S110...\n",
      "Processing D:\\bio_s\\med_pain\\S114...\n",
      "Processing D:\\bio_s\\med_pain\\S126...\n",
      "Processing D:\\bio_s\\med_pain\\S129...\n",
      "Processing D:\\bio_s\\med_pain\\S134...\n",
      "Feature DataFrame shape: (3117, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>segment_file</th>\n",
       "      <th>pain</th>\n",
       "      <th>corrugator_mean</th>\n",
       "      <th>corrugator_std</th>\n",
       "      <th>corrugator_rms</th>\n",
       "      <th>corrugator_max</th>\n",
       "      <th>corrugator_min</th>\n",
       "      <th>corrugator_median</th>\n",
       "      <th>corrugator_abs_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>zygomaticus_std</th>\n",
       "      <th>zygomaticus_rms</th>\n",
       "      <th>zygomaticus_max</th>\n",
       "      <th>zygomaticus_min</th>\n",
       "      <th>zygomaticus_median</th>\n",
       "      <th>zygomaticus_abs_mean</th>\n",
       "      <th>zygomaticus_zero_cross</th>\n",
       "      <th>zygomaticus_waveform_length</th>\n",
       "      <th>zygomaticus_mean_freq</th>\n",
       "      <th>zygomaticus_median_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S008</td>\n",
       "      <td>S008_0.mat</td>\n",
       "      <td>PL_1</td>\n",
       "      <td>-1.262862e-05</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>0.070712</td>\n",
       "      <td>-0.096127</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.008459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.004881</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>-0.034432</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>3284</td>\n",
       "      <td>26.311347</td>\n",
       "      <td>162.596924</td>\n",
       "      <td>139.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S008</td>\n",
       "      <td>S008_10.mat</td>\n",
       "      <td>PL_1</td>\n",
       "      <td>3.296219e-07</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>-0.007387</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>0.009383</td>\n",
       "      <td>0.064049</td>\n",
       "      <td>-0.058743</td>\n",
       "      <td>-0.000193</td>\n",
       "      <td>0.006405</td>\n",
       "      <td>2749</td>\n",
       "      <td>49.457604</td>\n",
       "      <td>159.198364</td>\n",
       "      <td>126.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S008</td>\n",
       "      <td>S008_100.mat</td>\n",
       "      <td>PL_1</td>\n",
       "      <td>-3.065771e-06</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.028406</td>\n",
       "      <td>-0.032078</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.011885</td>\n",
       "      <td>-0.008169</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>2740</td>\n",
       "      <td>9.698282</td>\n",
       "      <td>162.496185</td>\n",
       "      <td>127.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S008</td>\n",
       "      <td>S008_102.mat</td>\n",
       "      <td>PL_1</td>\n",
       "      <td>-1.011531e-05</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.004827</td>\n",
       "      <td>0.023616</td>\n",
       "      <td>-0.021280</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.020730</td>\n",
       "      <td>-0.013734</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>2558</td>\n",
       "      <td>8.506985</td>\n",
       "      <td>164.467671</td>\n",
       "      <td>128.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S008</td>\n",
       "      <td>S008_103.mat</td>\n",
       "      <td>PL_1</td>\n",
       "      <td>-1.658919e-06</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.068270</td>\n",
       "      <td>-0.089671</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>0.006460</td>\n",
       "      <td>0.100476</td>\n",
       "      <td>-0.086019</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>3162</td>\n",
       "      <td>25.398380</td>\n",
       "      <td>182.650932</td>\n",
       "      <td>165.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject  segment_file  pain  corrugator_mean  corrugator_std  \\\n",
       "0    S008    S008_0.mat  PL_1    -1.262862e-05        0.012943   \n",
       "1    S008   S008_10.mat  PL_1     3.296219e-07        0.001211   \n",
       "2    S008  S008_100.mat  PL_1    -3.065771e-06        0.005499   \n",
       "3    S008  S008_102.mat  PL_1    -1.011531e-05        0.004827   \n",
       "4    S008  S008_103.mat  PL_1    -1.658919e-06        0.004719   \n",
       "\n",
       "   corrugator_rms  corrugator_max  corrugator_min  corrugator_median  \\\n",
       "0        0.012943        0.070712       -0.096127           0.000888   \n",
       "1        0.001211        0.006373       -0.007387          -0.000044   \n",
       "2        0.005499        0.028406       -0.032078           0.000360   \n",
       "3        0.004827        0.023616       -0.021280           0.000043   \n",
       "4        0.004719        0.068270       -0.089671           0.000020   \n",
       "\n",
       "   corrugator_abs_mean  ...  zygomaticus_std  zygomaticus_rms  \\\n",
       "0             0.008459  ...         0.004881         0.004881   \n",
       "1             0.000933  ...         0.009383         0.009383   \n",
       "2             0.003943  ...         0.001688         0.001688   \n",
       "3             0.003596  ...         0.001527         0.001527   \n",
       "4             0.002037  ...         0.006460         0.006460   \n",
       "\n",
       "   zygomaticus_max  zygomaticus_min  zygomaticus_median  zygomaticus_abs_mean  \\\n",
       "0         0.033626        -0.034432            0.000245              0.002999   \n",
       "1         0.064049        -0.058743           -0.000193              0.006405   \n",
       "2         0.011885        -0.008169           -0.000051              0.001242   \n",
       "3         0.020730        -0.013734           -0.000026              0.001134   \n",
       "4         0.100476        -0.086019           -0.000060              0.003055   \n",
       "\n",
       "   zygomaticus_zero_cross  zygomaticus_waveform_length  zygomaticus_mean_freq  \\\n",
       "0                    3284                    26.311347             162.596924   \n",
       "1                    2749                    49.457604             159.198364   \n",
       "2                    2740                     9.698282             162.496185   \n",
       "3                    2558                     8.506985             164.467671   \n",
       "4                    3162                    25.398380             182.650932   \n",
       "\n",
       "   zygomaticus_median_freq  \n",
       "0                    139.3  \n",
       "1                    126.7  \n",
       "2                    127.9  \n",
       "3                    128.8  \n",
       "4                    165.8  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Data Loading & Feature Table Construction\n",
    "# ------------------------------------------------\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "\n",
    "def process_subject_segments(subject_folder, pain_label, artifact_threshold=ARTIFACT_THRESHOLD):\n",
    "    \"\"\"\n",
    "    For a given subject and pain level, process all .mat files:\n",
    "      - Bandpass filter both EMG channels\n",
    "      - Reject segments with artifacts\n",
    "      - Extract features for both channels\n",
    "      - Return list of feature dicts (one per segment)\n",
    "    \"\"\"\n",
    "    subject_id = os.path.basename(subject_folder)\n",
    "    feature_rows = []\n",
    "    for mat_path in glob.glob(os.path.join(subject_folder, '*.mat')):\n",
    "        try:\n",
    "            mat = loadmat(mat_path)\n",
    "            data = mat['data']  # shape (n_samples, 5)\n",
    "            row = {\n",
    "                'subject': subject_id,\n",
    "                'segment_file': os.path.basename(mat_path),\n",
    "                'pain': pain_label\n",
    "            }\n",
    "            artifacted = False\n",
    "            for i, ch in enumerate(EMG_COLS):\n",
    "                emg = data[:, ch]\n",
    "                emg_filt = apply_bandpass(emg, FS, BANDPASS[0], BANDPASS[1])\n",
    "                if artifact_rejection(emg_filt, artifact_threshold):\n",
    "                    artifacted = True\n",
    "                    break\n",
    "                feats = extract_features(emg_filt, FS)\n",
    "                for k, v in feats.items():\n",
    "                    row[f'{EMG_LABELS[i]}_{k}'] = v\n",
    "            if not artifacted:\n",
    "                feature_rows.append(row)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {mat_path}: {e}\")\n",
    "    return feature_rows\n",
    "\n",
    "# Aggregate for all subjects and both pain levels\n",
    "all_features = []\n",
    "for pain_folder, label in PAIN_LEVELS.items():\n",
    "    folder_path = os.path.join(DATA_ROOT, pain_folder)\n",
    "    for subj in sorted(os.listdir(folder_path)):\n",
    "        subj_folder = os.path.join(folder_path, subj)\n",
    "        if os.path.isdir(subj_folder):\n",
    "            print(f\"Processing {subj_folder}...\")\n",
    "            feat_rows = process_subject_segments(subj_folder, label)\n",
    "            all_features.extend(feat_rows)\n",
    "\n",
    "# Build DataFrame\n",
    "df_features = pd.DataFrame(all_features)\n",
    "print(\"Feature DataFrame shape:\", df_features.shape)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91494ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=4):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def apply_bandpass(data, fs, lowcut=20, highcut=450, order=4):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    return filtfilt(b, a, data)\n",
    "\n",
    "def artifact_rejection(emg_signal, threshold=1000):\n",
    "    \"\"\"\n",
    "    Returns True if the signal contains amplitudes above the artifact threshold.\n",
    "    \"\"\"\n",
    "    return np.any(np.abs(emg_signal) > threshold)\n",
    "\n",
    "def extract_features(emg_signal, fs):\n",
    "    \"\"\"\n",
    "    Extracts time and frequency domain features from an EMG signal segment.\n",
    "    Returns: dict of feature names and values.\n",
    "    \"\"\"\n",
    "    feats = {}\n",
    "    feats['mean'] = np.mean(emg_signal)\n",
    "    feats['std'] = np.std(emg_signal)\n",
    "    feats['rms'] = np.sqrt(np.mean(emg_signal ** 2))\n",
    "    feats['max'] = np.max(emg_signal)\n",
    "    feats['min'] = np.min(emg_signal)\n",
    "    feats['median'] = np.median(emg_signal)\n",
    "    feats['abs_mean'] = np.mean(np.abs(emg_signal))\n",
    "    feats['zero_cross'] = int(((emg_signal[:-1] * emg_signal[1:]) < 0).sum())\n",
    "    feats['waveform_length'] = np.sum(np.abs(np.diff(emg_signal)))\n",
    "    # Frequency-domain features\n",
    "    fft_vals = np.abs(np.fft.rfft(emg_signal))\n",
    "    fft_freq = np.fft.rfftfreq(len(emg_signal), 1/fs)\n",
    "    if np.sum(fft_vals) > 0:\n",
    "        feats['mean_freq'] = np.sum(fft_freq * fft_vals) / np.sum(fft_vals)\n",
    "        median_freq_idx = np.where(np.cumsum(fft_vals) >= np.sum(fft_vals)/2)[0][0]\n",
    "        feats['median_freq'] = fft_freq[median_freq_idx]\n",
    "    else:\n",
    "        feats['mean_freq'] = 0.0\n",
    "        feats['median_freq'] = 0.0\n",
    "    return feats\n",
    "\n",
    "def extract_features_from_mat_file(mat, fs, artifact_threshold=1000, emg_cols=[0,1], emg_labels=['corrugator', 'zygomaticus']):\n",
    "    \"\"\"\n",
    "    Given a loaded .mat file dict, returns features for both EMG channels.\n",
    "    Returns None if artifact found in any channel.\n",
    "    \"\"\"\n",
    "    data = mat['data']\n",
    "    features = {}\n",
    "    for i, ch in enumerate(emg_cols):\n",
    "        emg = data[:, ch]\n",
    "        emg_filt = apply_bandpass(emg, fs)\n",
    "        if artifact_rejection(emg_filt, artifact_threshold):\n",
    "            return None  # artifact: skip this segment\n",
    "        feats = extract_features(emg_filt, fs)\n",
    "        for k, v in feats.items():\n",
    "            features[f\"{emg_labels[i]}_{k}\"] = v\n",
    "    return features\n",
    "\n",
    "# Usage example (requires scipy.io.loadmat and a loaded .mat file):\n",
    "# from scipy.io import loadmat\n",
    "# mat = loadmat('bio_s/low_pain/S001/S001_0.mat')\n",
    "# feats = extract_features_from_mat_file(mat, fs=1000)\n",
    "# print(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ae3e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Make sure to import all functions from feature_extraction.py here or paste them above this code:\n",
    "# - apply_bandpass\n",
    "# - artifact_rejection\n",
    "# - extract_features\n",
    "\n",
    "def extract_features_from_dataset(\n",
    "    data_root,\n",
    "    pain_levels,\n",
    "    emg_cols,\n",
    "    emg_labels,\n",
    "    fs=1000,\n",
    "    bandpass=(20, 450),\n",
    "    artifact_threshold=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Loops through all subjects, segments, and pain levels in the dataset\n",
    "    and extracts features for each valid segment.\n",
    "\n",
    "    Returns a DataFrame with one row per segment.\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    for pain_folder, pain_label in pain_levels.items():\n",
    "        folder_path = os.path.join(data_root, pain_folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        for subj in sorted(os.listdir(folder_path)):\n",
    "            subj_folder = os.path.join(folder_path, subj)\n",
    "            if not os.path.isdir(subj_folder):\n",
    "                continue\n",
    "            for mat_path in glob.glob(os.path.join(subj_folder, '*.mat')):\n",
    "                try:\n",
    "                    mat = loadmat(mat_path)\n",
    "                    row = {\n",
    "                        'subject': subj,\n",
    "                        'segment_file': os.path.basename(mat_path),\n",
    "                        'pain': pain_label\n",
    "                    }\n",
    "                    artifacted = False\n",
    "                    for i, ch in enumerate(emg_cols):\n",
    "                        emg = mat['data'][:, ch]\n",
    "                        emg_filt = apply_bandpass(emg, fs, bandpass[0], bandpass[1])\n",
    "                        if artifact_rejection(emg_filt, artifact_threshold):\n",
    "                            artifacted = True\n",
    "                            break\n",
    "                        feats = extract_features(emg_filt, fs)\n",
    "                        for k, v in feats.items():\n",
    "                            row[f\"{emg_labels[i]}_{k}\"] = v\n",
    "                    if not artifacted:\n",
    "                        all_rows.append(row)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {mat_path}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    return df\n",
    "\n",
    "# Usage example:\n",
    "# df_features = extract_features_from_dataset(\n",
    "#     DATA_ROOT, PAIN_LEVELS, EMG_COLS, EMG_LABELS, FS, BANDPASS, ARTIFACT_THRESHOLD\n",
    "# )\n",
    "# print(df_features.shape)\n",
    "# df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afe769dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Make sure to import all functions from feature_extraction.py here or paste them above this code:\n",
    "# - apply_bandpass\n",
    "# - artifact_rejection\n",
    "# - extract_features\n",
    "\n",
    "def extract_features_from_dataset(\n",
    "    data_root,\n",
    "    pain_levels,\n",
    "    emg_cols,\n",
    "    emg_labels,\n",
    "    fs=1000,\n",
    "    bandpass=(20, 450),\n",
    "    artifact_threshold=1000\n",
    "):\n",
    "    \"\"\"\n",
    "    Loops through all subjects, segments, and pain levels in the dataset\n",
    "    and extracts features for each valid segment.\n",
    "\n",
    "    Returns a DataFrame with one row per segment.\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    for pain_folder, pain_label in pain_levels.items():\n",
    "        folder_path = os.path.join(data_root, pain_folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "        for subj in sorted(os.listdir(folder_path)):\n",
    "            subj_folder = os.path.join(folder_path, subj)\n",
    "            if not os.path.isdir(subj_folder):\n",
    "                continue\n",
    "            for mat_path in glob.glob(os.path.join(subj_folder, '*.mat')):\n",
    "                try:\n",
    "                    mat = loadmat(mat_path)\n",
    "                    row = {\n",
    "                        'subject': subj,\n",
    "                        'segment_file': os.path.basename(mat_path),\n",
    "                        'pain': pain_label\n",
    "                    }\n",
    "                    artifacted = False\n",
    "                    for i, ch in enumerate(emg_cols):\n",
    "                        emg = mat['data'][:, ch]\n",
    "                        emg_filt = apply_bandpass(emg, fs, bandpass[0], bandpass[1])\n",
    "                        if artifact_rejection(emg_filt, artifact_threshold):\n",
    "                            artifacted = True\n",
    "                            break\n",
    "                        feats = extract_features(emg_filt, fs)\n",
    "                        for k, v in feats.items():\n",
    "                            row[f\"{emg_labels[i]}_{k}\"] = v\n",
    "                    if not artifacted:\n",
    "                        all_rows.append(row)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {mat_path}: {e}\")\n",
    "\n",
    "    df = pd.DataFrame(all_rows)\n",
    "    return df\n",
    "\n",
    "# Usage example:\n",
    "# df_features = extract_features_from_dataset(\n",
    "#     DATA_ROOT, PAIN_LEVELS, EMG_COLS, EMG_LABELS, FS, BANDPASS, ARTIFACT_THRESHOLD\n",
    "# )\n",
    "# print(df_features.shape)\n",
    "# df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "062c412e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "def run_leave_one_subject_out_rf(df_features, emg_labels=['corrugator', 'zygomaticus']):\n",
    "    \"\"\"\n",
    "    Runs Random Forest with leave-one-subject-out cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        preds: predicted labels\n",
    "        probs: predicted probabilities\n",
    "        y_true: true labels\n",
    "        groups: subject IDs\n",
    "    \"\"\"\n",
    "    # Select features\n",
    "    feature_cols = [c for c in df_features.columns if any(e in c for e in emg_labels)]\n",
    "    X = df_features[feature_cols].values\n",
    "    y = (df_features['pain'] == 'PL_2').astype(int).values  # 1 for medium pain, 0 for low pain\n",
    "    groups = df_features['subject'].values\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Leave-One-Group-Out (subject as group)\n",
    "    logo = LeaveOneGroupOut()\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    cal_rf = CalibratedClassifierCV(rf, method='isotonic', cv=3)\n",
    "\n",
    "    preds = np.zeros(len(y))\n",
    "    probs = np.zeros(len(y))\n",
    "    for fold, (train_idx, test_idx) in enumerate(logo.split(X_scaled, y, groups)):\n",
    "        cal_rf.fit(X_scaled[train_idx], y[train_idx])\n",
    "        preds[test_idx] = cal_rf.predict(X_scaled[test_idx])\n",
    "        probs[test_idx] = cal_rf.predict_proba(X_scaled[test_idx])[:,1]\n",
    "        print(f\"Fold {fold+1}: Subject {groups[test_idx][0]} - Acc: {accuracy_score(y[test_idx], preds[test_idx]):.3f}\")\n",
    "\n",
    "    print(\"Overall Accuracy:\", accuracy_score(y, preds))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y, probs))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y, preds))\n",
    "\n",
    "    return preds, probs, y, groups\n",
    "\n",
    "# Example usage:\n",
    "# preds, probs, y_true, groups = run_leave_one_subject_out_rf(df_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
